{"title":"Solution","markdown":{"headingText":"Solution","containsRefs":false,"markdown":"\nIn the following sections we describe our recommendations for:\n* Increasing semantic interoperability between tools in the EconDataverse\n* Linking data to other data and metadata\n* Constraining data and metadata using ontologies\n* Developing new tools that rely on semantic interoperability, linked data, and ontologies to streamline economic data reuse\n\n## Semantic interoperability\n\nThe EconDataverse is both a set of software tools in R and Python and a set of conventions and best practices for developing tools that work with economic data. There are coding conventions that ensure consistent style across packages as well as data syntax conventions that ensure compatibility with popular data manipulation and visualization libraries in both R and Python.\n\nInteroperability between tools in the EconDataverse is a key concern. Software tools that do not interoperate create additional toil for the user, contrary to our stated goal of eliminating toil. In the EconDataverse the problem of interoperability is one of ensuring the tools \"speak the same language\". A simple approach to this problem is to consider language as equivalent to syntax, and ensure that tools consume and produce the same syntax, such as the tidy CSV (TKTK ref) currently used by tools in the EconDataverse. This reduces the toil associated with transforming syntax between tools but leaves the problem of **semantic interoperability**. \n\nIn this context semantic interoperability is the ability of different tools in the EconDataverse to exchange data with unambiguous, shared meaning. It ensures that the meaning of the data is preserved and correctly interpreted between tools, even if those tools use different technologies, such as R and Python.\n\nSemantic interoperability starts from agreeing on unambiguous identifiers for things. For example, the EconDataverse package maintainers have agreed to refer to countries using [ISO 3166-1 standard codes](TKTK ref) and to represent years using four digits and the Gregorian calendar. This consensus ensures that data from different sources about the same countries and years can be joined, as in the R example below:\n\n<!-- Teal: ChatGPT generated this example. Would be great to have a better one along the same lines. -->\n\n```r\n# Load required package\nlibrary(dplyr)\n\n# --- Macroeconomic dataset: GDP (in USD billions) ---\nmacro_data <- data.frame(\n  iso3c = c(\"USA\", \"FRA\", \"DEU\", \"JPN\"),\n  year = c(2024, 2024, 2024, 2024),\n  gdp_billion = c(27300, 3100, 4600, 5100)\n)\n\n# --- Population dataset: Population (in millions) ---\npopulation_data <- data.frame(\n  iso3c = c(\"USA\", \"FRA\", \"DEU\", \"BRA\"),\n  year = c(2024, 2024, 2024, 2024),\n  population_million = c(334, 67, 84, 215)\n)\n\n# --- Perform inner join on ISO country code and year ---\njoined_data <- inner_join(macro_data, population_data, by = c(\"iso3c\", \"year\"))\n```\n\nImagine instead that different datasets used different identifiers for countries: one dataset referred to the United States as \"États-Unis\" while the other referred to it as \"USA\":\n\n```r\n# --- Macroeconomic dataset: GDP (in USD billions) ---\nmacro_data <- data.frame(\n  iso3c = c(\"États-Unis\", \"FRA\", \"DEU\", \"JPN\"),\n  year = c(2024, 2024, 2024, 2024),\n  gdp_billion = c(27300, 3100, 4600, 5100)\n)\n\n# --- Population dataset: Population (in millions) ---\npopulation_data <- data.frame(\n  iso3c = c(\"USA\", \"FRA\", \"DEU\", \"BRA\"),\n  year = c(2024, 2024, 2024, 2024),\n  population_million = c(334, 67, 84, 215)\n)\n\n# Join on USA data is not going to work as intended here.\n```\n\nThe data analyst would have to first resolve the discrepancy -- mapping \"États-Unis\" to \"USA\" or vice versa -- in order to harmonize data from multiple sources. That work is toil that can be eliminated by agreeing on unambiguous identifiers and using them consistently.\n\n### Uniquely identifying numeric data\n\nThe R example in [figure X](TKTK ref) also includes numeric data such as GDP (in billions of of US Dollars) and population (in millions). Unlike the ISO 3166 country codes, these data are ambiguous. A human data analyst can infer at least part of the meaning from the column name (gdp_billion) and the accompanying comment (\"GDP (in USD billions)\"). Other parts are still ambiguous -- is it nominal or real GDP?\n\nWe would like to eliminate this ambiguity and the ensuing toil by associating numeric data with unambiguous metadata. The [SDMX Information Model](TKTK ref) recommends that the metadata for a numeric datum include:\n\n* [Dimensions](TKTK ref) whose combined values uniquely identify that datum in a [cube/hypercube of dimensions](TKTK ref OLAP Cube)\n* [Attributes](TKTK ref) of the datum, such as units of measurement\n\nThe dimensions uniquely identifying a single nominal GDP measurement are:\n\n1. Place: the country associated with the GDP (e.g., \"USA\" and \"FRA\")\n2. Time: the year the GDP was measured (e.g., 2024).\n3. Indicator: nominal GDP\n\nDimensions like \"place\" and attributes like \"unit of measurement\" should themselves be uniquely identified, and have associated properties such as human-readable labels and definitions, relationships with other dimensions or attributes, and constraints on the values that can be associated with a dimension (e.g., [code lists](TKTK ref)). The [SDMX Content-Oriented Guidelines](TKTK ref) provide a library of well-known, uniquely-identified dimensions and attributes that can be reused in many different domains.\n\n## Linking data\n\nWe can use the unambiguous identifier for a thing (\"USA\") in the data as a key to resolve additional properties about a thing as well as its relationships with other things following the [Linked Data principles](http://linkeddatabook.com/editions/1.0/). For example, we can use [schema.org](https://schema.org) vocabularies to describe the relationship between the country of the United States and the continent of North America, in a machine-readable format (an [RDF](TKTK ref) [knowledge graph](TKTK ref) represented in [Turtle](TKTK ref)):\n\n```ttl\n@prefix ex: <http://example.org/entities/> .\n@prefix schema: <https://schema.org/> .\n\n# United States of America\nex:USA a schema:Country ;\n    # Human-readable labels in multiple human languages\n    schema:name \"United States of America\"@en ;\n    schema:name \"États-Unis\"@fr ;\n    schema:identifier \"USA\" ;\n    # A relationship: the country United States is contained in the place North America.\n    schema:containedInPlace ex:NA .\n\n# North America\nex:NA a schema:Continent ;\n    schema:name \"North America\"@en ;\n    schema:identifier \"NA\" .\n```\n\n## Constraining data and metadata\n\nThere is an additional level of consensus at work in the example above. By referencing schema.org we are implicitly agreeing that the unambiguous identifier `schema:containedInPlace` refers to a way of relating two places. That identifier can be used in turn as a key to further (linked) metadata:\n\n```ttl\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix schema: <https://schema.org/> .\n\nschema:containedInPlace a rdf:Property ;\n    rdfs:label \"containedInPlace\" ;\n    rdfs:comment \"The basic containment relation between a place and one that contains it.\" ;\n    schema:domainIncludes schema:Place ;\n    schema:inverseOf schema:containsPlace ;\n    schema:rangeIncludes schema:Place .\n```\n\nThis metadata is part of an **ontology**. An ontology is an \"explicit specification of a conceptualization\" (TKTK ref Gruber) of a domain, including the \"the types, properties, and interrelationships of entities that exist for a particular domain of discourse\" (TKTK ref Gene Ontology Consortium). An ontology includes machine-readable specifications as well as human-readable labels and definitions that codify shared understanding of a domain. In the snippet above the domain is geography -- places and a valid relationship (contained-in) between them. The ontology is not about specific places, but about the category \"place\", its possible properties, and how it relates to other categories. The example eliminates ambiguity what `schema:containedIn` means through the use of a human-readable definition (\"The basic containment relation ...\") as well as machine-enforceable **constraints** on the categories of things that can be involved in the `schema:containedInPlace` relation (the `schema:domainIncludes` and `schema:rangeIncludes`). By constraining the domain of discourse an ontology amplifies the benefits of reusing identifiers by providing further clarity to humans as well as a way for machines to ensure that data and metadata stay within those constraints.\n\n### An ontology of economics\n\nOntologies like the [Financial Industry Business Ontology](https://spec.edmcouncil.org/fibo/) are commonly used in the financial services sector to enable cross-system federation and aggregation of data in order to support decision-making, streamline regulatory reporting, and encourage the adoption of advanced analytical capabilities.\n\nUnfortunately, the macroeconomics domain does not have an ontology comparable in scope and rigour to FIBO. We recommend developing an ontology of macroeconomics incrementally. At a minimum this ontology should model:\n\n* the structure of statistical data cubes (dimensions, attributes, measures)\n* common dimensions such as time, place, and macroeconomic indicators\n* common attributes such as units\n\nIn the long term the ontology should also model:\n\n* relationships between dimensions e.g., different macroeconomic indicators\n* relationships between attributes e.g., unit conversions\n* data lineage and provenance\n* modeling assumptions\n* information about economic organizations, people, and the relationships between them (a [social network](TKTK ref))\n* information about places and their relationships (e.g., aggregates such as Low Income Countries)\n* machine-readable assertions extracted from human-written web pages and other documents (a [knowledge graph](TKTK ref) about the economic world)\n\nFortunately, there are a number of existing standards that can serve as building blocks for the ontology, including:\n\n* [SDMX Data Structure Definitions (DSDs)](TKTK ref) e.g., [Balance of Payments (SDMX-BOP and Foreign Debt Investments (SDMX-FDI)](https://sdmx.org/sdmx-data-structure-definitions-for-balance-of-payments-sdmx-bop/)\n* the [RDF Data Cube Vocabulary](https://www.w3.org/TR/vocab-data-cube/) for publishing multi-dimensional statistical data as [Linked Data](TKTK ref)\n* the [PROV Ontology](https://www.w3.org/TR/prov-o/) of data lineage and provenance\n* [QUDT](https://qudt.org) ontologies of units of measure, quantity kind, dimensions and data types\n* [SKOS](https://www.w3.org/2004/02/skos/) specifications and standards for knowledge organization systems (KOS) (thesauri, taxonomies, et al.)\n* the [VoID vocabulary](https://www.w3.org/TR/void/) for describing linked datasets\n* [Schema.org](https://schema.org) cross-domain vocabularies\n\n## Tools to streamline economic data reuse\n\nIncreasing semantic interoperability, developing ontologies, and taking advantage of linked data will reduce the toil and increase the productivity of using existing tools in the EconDataverse. However, in order to fully address the challenges highlighted in [TKTK section ref](), we also recommend expanding and refining the EconDataverse toolkit in three key areas:\n\n* tools for extracting and transforming economic data and metadata\n* tools for exploring and finding economic data and metadata\n* tools for analyzing and manipulating financial models\n\nNew tools in these areas should produce and consume data and metadata that conform to the ontology in order to enable new features, like providing unified views over heterogeneous data sources.\n\nFor the short- to mid-term we recommend implementing an adapter library and command-line program that transforms ontology-conformant data to and from the formats expected by existing EconDataverse tools. In the long term these tools should be retrofitted to produce and consume ontology-conformant data and metadata.\n\n### Tools for extracting and transforming economic data and metadata\n\nThe majority of packages in the current EconDataverse package ecosystem extract data from IMF, World Bank, and other sources and transform them into [tidy](TKTK ref) data frames, with each variable as a column and each observation as a row. Metadata are typically limited to column names, which are not explicitly grounded in an ontology that would provide context and definitions.\n\nGoing forward, these packages should produce ontology-conformant data and metadata that fully capture the semantics of the source data. These can be easily but lossily transformed into convenient but semantics-poor formats like tidy data frames for compatibility with third party tools.\n\nExtraction should not be limited to tabular data sources. The ontology can also be used to guide Large Language Models (LLMs) in the extraction of ontology-conformant structured data from natural language sources such as the [World Bank country and climate development reports](TKTK ref).\n\n### Tools for exploring and finding economic data and metadata\n\nTools for exploring and finding data and metadata tend to be useful in proportion to how closely the data's representation corresponds to the domain abstractions, like accounts and sub-accounts in Balance of Payments datasets. This requires a level of abstraction and interpretation that is difficult to achieve without building data source-specific tools. Instead, most generic tools work with data and metadata at the lowest common denominator of abstraction -- as tables and rows of figures to be scanned or a corpus of arbitrary text to be searched. The problem of interpretation is mostly left up to the user.\n\nHaving data and metadata from multiple sources conform to a rich, domain-specific ontology makes it possible to build tools that work at a higher level of abstraction without sacrificing source independence. Tools can make assumptions about the meaning of the data and relationships between them, which dramatically increases the tools' power. For example, the next generation of EconDataverse tools could:\n\n* group or aggregate data from different (geographic) reference areas by considering explicit relationships between areas, such as part-whole or collection membership \n* let users browse and filter cube-structured datasets and slices by the dimensions they incorporate (e.g., time, place, gender), provenance, or recency\n* suggest inputs for a given model by matching metadata about the inputs with metadata from a data/metadata catalog\n\n### Tools for analyzing and manipulating financial models\n\nFinally, the EconDataverse needs tools for analyzing and financial models, which are typically encoded in Excel spreadsheets. In the short term, tools should automate or semi-automate toilsome tasks like:\n\n* Manually mapping statistical data cube measures to spreadsheet inputs\n* Manually reverse-engineering spreadsheets to identify which inputs are required for a subset of desired outputs, in order to avoid spending time populating redundant inputs\n* Manually permuting spreadsheets inputs in order to perform sensitivity analyses\n\n### Disambiguating inputs\n\nMuch of the toil in using financial models lies in the process of identifying the right source data to supply as model inputs. For example, the Debt Dynamics Toolkit spreadsheet requires the following inputs in a single sheet:\n\n| Year / Variable | 2011  | 2012  |\n|----------------|-------|-------|\n| dt (debt including uncalled guarantees): stock of total gross public debt, percent of GDP | 31.59 | 35.34 |\n| o/w stock of local-currency guarantees (uncalled): stock of uncalled guarantees in local currency included in total debt, percent of GDP | 0.00 | 0.00 |\n| o/w stock of foreign-currency guarantees (uncalled): stock of uncalled guarantees in foreign currency included in total debt, percent of GDP | 0.00 | 0.00 |\n| αt (share excl. guarantees): share of foreign currency denominated debt in total debt, percent of total debt | 55.05 | 58.87 |\n| et (LCU/FCU, avg): nominal average exchange rate, local currency per unit of foreign currency | 18.92 | 19.50 |\n| et (LCU/FCU, eop): nominal end of period exchange rate, local currency per unit of foreign currency | 19.05 | 19.96 |\n| itd: nominal effective interest rate on local currency denominated debt, percent | 8.92  | 9.23  |\n| itf: nominal effective interest rate on foreign currency denominated debt, percent | 2.46  | 2.03  |\n| πt: GDP deflator inflation, percent | 5.60  | 5.39  |\n| gt: Real GDP growth, percent | 3.84  | 4.13  |\n| pbt: Primary balance, percent of GDP | -3.28 | -4.03 |\n| oft (other net debt-creating flows): Other net debt creating flows, percent of GDP | 0.00  | 0.00  |\n| πft: Foreign GDP deflator inflation, percent (used in fan chart) | 2.09  | 1.92  |\n\n: Dynamic Debt Toolkit inputs sheet {.bordered .striped .hover}\n\nPer the [data cube model](TKTK ref), each input cell can be uniquely identified by dimensions:\n\n* Time: with controlled values 2011 and 2012\n* Place: implicitly, the country whose debt is being analyzed\n* Indicator: such as \"Real GDP growth\"\n\nIn this case the year and place are unambiguously identified and are relatively easy to match to source data. It is not as obvious how to map the indicator \"nominal effective interest rate on foreign currency denominated debt, percent\" to a specific source database.\n\nOne approach is to treat \"nominal effective interest rate on foreign currency denominated debt, percent\" as a unique identifier as-is, like [Google Data Commons]() does. This assumes that the source data sources are also using this identifier, which is unlikeliy.\n\nThe approach we recommend is to decompose the name into a structured combination of sub-identifiers:\n\n* a base indicator: \"interest rate\"\n* qualifiers on the base indicator: \"nominal\", \"effective\", \"on foreign currency denominated debt\"\n* attributes: \"percent\", which should be treated as an attribute of the data rather than as part of the indicator dimension\n\nThe structure and valid combinations of indicator, qualifier, and attribute values should be dictated by the ontology. Given a permissible set of controlled values, a Large Language Model could aid in this decomposition from natural language.\n\nThis approach parallels the way World Bank debt codes can be decomposed into segments. For example, `DT.DOD.[Debt Instrument].[Debtor/Creditor Sector].[Unit]` can be decomposed into: \n\n* DT: Debt\n* DOD: Debt Outstanding and Disbursed\n* Instrument Type (e.g., long-term, short-term, use of IMF credit)\n* Debtor or Creditor (e.g., public, private, multilateral, bilateral)\n* Unit of measure (e.g., CD = current US dollars, GD.ZS = % of GNI)\n\n### Models as data\n\nIn the long term the financial models themselves should be treated as data, and extracted and transformed into ontology-conformant data and metadata. From there they could be lossily transformed back into spreadsheets. This approach would build on open source precedents like [Morphir](https://morphir.finos.org/), a system that captures an application's domain model and business logic in a technology agnostic manner.\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"solution.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","bibliography":["../references.bib"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}